---
title: "HW6"
author: "Ruihan Ding"
date: "2025-12-03"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
```

# Problem 1

Import and clean the data.

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv") |> 
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = if_else(
      disposition == "Closed by arrest", 1, 0
    ),
    victim_age = as.numeric(victim_age),
    victim_sex = fct_relevel(victim_sex, "Female")
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    victim_sex %in% c("Female", "Male")
  )
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors.

```{r}
fit_Baltimore = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = _, family = binomial())

fit_Baltimore |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(
    OR = exp(estimate),
    conf.low = exp(conf.low),
    conf.high = exp(conf.high)
  ) |> 
  knitr::kable()
```

The adjusted odds ratio for having a homicide solved, comparing male victims to female victims while holding all other variables constant, is 0.43 with a 95% confidence interval of (0.32, 0.56).

Run glm for each of the cities in the dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims.

```{r}
fit_all = 
  homicide_df |> 
  select(city_state, victim_race, victim_age, victim_sex, resolved) |> 
  nest(data = -city_state) |> 
  mutate(
    fit = map(data, \(df) glm(
    resolved ~ victim_age + victim_race + victim_sex,
    data = df,
    family = binomial()
    )),
  results = map(fit, broom::tidy, conf.int = TRUE)
  ) |> 
  select(city_state, results) |> 
  unnest(results) |> 
  mutate(
    OR = exp(estimate),
    conf.low = exp(conf.low),
    conf.high = exp(conf.high)
  ) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, conf.low, conf.high)

fit_all
```

Create a plot that shows the estimated ORs and CIs for each city.

```{r}
fit_all |> 
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) |> 
  ggplot(aes(x = city_state, y = OR)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted OR (Male vs Female)",
    title = "Adjusted odds ratios for solving homicides by city"
  ) +
  theme_minimal()
```

For the majority of cities, the estimated OR is below 1, indicating that homicides involving male victims generally have lower odds of being solved than those involving female victims after adjustment.

# Problem 2

Import data.

```{r}
library(p8105.datasets)
data("weather_df")
```

Do bootstrapping.

```{r}
bootstrap_results = 
  weather_df |> 
  bootstrap(n = 5000) |> 
  mutate(
    df = map(strap, as_tibble),
    fits = map(df, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results1 = map(fits, broom::glance),
    results2 = map(fits, broom::tidy)
  ) |> 
  mutate(
    r2 = map_dbl(results1, "r.squared"),
    b1 = map_dbl(results2, \(df) df$estimate[2]),
    b2 = map_dbl(results2, \(df) df$estimate[3]),
    beta_ratio = b1/b2
  ) |> 
  select(.id, r2, beta_ratio)
```

Plot the distribution of the estimates.

```{r}
bootstrap_results |> 
  ggplot(aes(x = r2)) +
  geom_density() +
  theme_minimal() +
  labs(
    x = expression(r^2),
    y = "Frequency",
    title = "Bootstrap distribution of R-squared"
  )

bootstrap_results |> 
  ggplot(aes(x = beta_ratio)) +
  geom_density() +
  theme_minimal() +
  labs(
    x = expression(beta[1] / beta[2]),
    y = "Frequency",
    title = expression("Bootstrap distribution of " ~ beta[1] / beta[2])
  )
```

Both bootstrap distributions are clearly skewed rather than symmetric, so a normal-theory approximation is not ideal. For r2, the bootstrap values are tightly concentrated around about 0.94, indicating consistently high explained variation. For b1/b2, most estimates lie roughly between −400 and −100, centered at a negative value. This skewness in both summaries motivates using the bootstrap distribution directly to obtain confidence intervals.

Identify the 95% confidence interval of the estimates.

```{r}
bootstrap_results |> 
  pivot_longer(
    r2:beta_ratio,
    names_to = "estimate",
    values_to = "value"
  ) |> 
  group_by(estimate) |> 
  summarize(
    CI_lower = quantile(value, 0.025),
    CI_upper = quantile(value, 0.975)
  ) |> 
  knitr::kable()
```

# Problem 3

Import and clean data.

```{r}
bwt_df =
  read_csv("data/birthweight.csv") |> 
  mutate(
    babysex = factor(babysex, 
                     levels = c(1, 2), 
                     labels = c("male", "female")),
    malform = factor(malform,
                     levels = c(0, 1),
                     labels = c("absent", "present")),
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown"))
  ) |> 
  drop_na() |> 
  filter(mrace != "Unknown",
         frace != "Unknown")
```

Build initial model.

```{r}
bwt_model_0 = 
  bwt_df |> 
  lm(
    bwt ~ babysex + bhead + blength +
      delwt + fincome + frace +
      gaweeks + malform +
      menarche + mheight + momage + mrace +
      parity + pnumlbw + pnumsga +
      ppbmi + ppwt +
      smoken + wtgain,
    data = _
  )
```

Exclude insignificant variables.

```{r}
bwt_model_0 |>
  broom::tidy() |> 
  drop_na() |> 
  filter(
    term != "(Intercept)", p.value < 0.05
  )

bwt_model_1 = 
  bwt_df |> 
  lm(
    bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken,
    data = _
  )

bwt_model_1 |> 
  broom::tidy()
```

Look at residuals.

```{r}
bwt_df = 
  bwt_df |> 
  add_residuals(bwt_model_1) |> 
  add_predictions(bwt_model_1)

bwt_df |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residuals vs fitted values for birthweight model"
  ) +
  theme_minimal()
```

The residuals are roughly centered around zero with no strong pattern across fitted birthweights, suggesting the linearity assumption is reasonable and variance is approximately constant. A few large residuals appear as outliers, but there is no obvious severe violation of model assumptions.















